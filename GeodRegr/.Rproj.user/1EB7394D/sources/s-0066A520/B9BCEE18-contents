Q <- function(s, x) {
  return(zipfR::Rgamma(s, x, lower = F))
}

Qinv <- function(s, x) {
  return(zipfR::Rgamma.inv(s, x, lower = F))
}

P <- function(s, x) {
  return(zipfR::Rgamma(s, x, lower = T))
}

Pinv <- function(s, x) {
  return(zipfR::Rgamma.inv(s, x, lower = T))
}

uppergamma <- function(s, x) {
  return(zipfR::Igamma(s, x, lower = F))
}

lowergamma <- function(s, x) {
  return(zipfR::Igamma(s, x, lower = T))
}

#' Approximate ARE of an M-type estimator to the least-squares estimator
#'
#' Approximate asymptotic relative efficiency (ARE) of an M-type estimator to the
#' least-squares estimator calculated using a tangent space approximation, given
#' Gaussian errors.
#'
#'
#'
#' @param estimator M-type estimator (\code{'l2'}, \code{'l1'}, \code{'huber'},
#'  or \code{'tukey'}).
#' @param k Dimension of the manifold.
#' @param c Positive multiplier of \eqn{\sigma}, the square root of the variance,
#'  used in the cutoff parameter for the \code{'huber'} and \code{'tukey'}
#'  estimators; should be \code{NULL} for the \code{'l2'} or \code{'l1'}
#'  estimators.
#' @return Approximate ARE
#' @references Shin H.-Y., Oh H.-S. (2020). Robust Geodesic Regression. <arXiv>
#' @author Ha-Young Shin
#' @seealso \code{\link{areNR}}.
#' @examples
#' are('l1', 10)
#' are('huber', 2, c = 1.50114)
#'
#' @export
are <- function(estimator, k, c = NULL) {
  if (((estimator == 'huber') | (estimator == 'tukey')) & is.null(c)) {
    stop('a c value must be provided if the chosen m-estimator is huber or tukey')
  }
  if (!is.null(c)) {
    if ((estimator == 'l2') | (estimator == 'l1')) {
      warning('l2 and l1 do not use a c value')
    }
    if (c <= 0) {
      stop('c must be positive')
    }
  }
  if ((k %% 1 != 0) | (k < 1)) {
    stop('k must be a positive integer')
  }
  if (estimator == 'l2') {
    result <- 1
  } else if (estimator == 'l1') {
    result <- ((gamma((k + 1) / 2))^2) / ((gamma(k / 2) * gamma((k + 2) / 2)))
  } else if (estimator == 'huber') {
    if (k == 1) {
      numfactor <- (k / 2) * lowergamma(k / 2, 0.5 * c^2)
    } else {
      numfactor <- (k / 2) * lowergamma(k / 2, 0.5 * c^2) + c * (k - 1) * (2^-1.5) * uppergamma((k - 1) / 2, 0.5 * c^2)
    }
    denfactor <- lowergamma((k + 2) / 2, 0.5 * c^2) + (0.5 * c^2) * uppergamma(k / 2, 0.5 * c^2)
    result <- (numfactor^2) / (gamma((k + 2) / 2) * denfactor)
  } else if (estimator == 'tukey') {
    numfactor <- (2 * (k + 4) / (c^4)) * lowergamma((k + 4) / 2, 0.5 * c^2) - (2 * (k + 2) / (c^2)) * lowergamma((k + 2) / 2, 0.5 * c^2) + (k / 2) * lowergamma(k / 2, 0.5 * c^2)
    denfactor <- lowergamma((k + 2) / 2, 0.5 * c^2) - (8 / (c^2)) * lowergamma((k + 4) / 2, 0.5 * c^2) + (24 / (c^4)) * lowergamma((k + 6) / 2, 0.5 * c^2) - (32 / (c^6)) * lowergamma((k + 8) / 2, 0.5 * c^2) + (16 / (c^8)) * lowergamma((k + 10) / 2, 0.5 * c^2)
    result <-  (numfactor^2) / (gamma((k + 2) / 2) * denfactor)
  } else {
    stop('the M-estimator must be one of l2, l1, huber, or tukey')
  }
  return(result)
}

deriv <- function(estimator, k, c) {
  if (c <= 0) {
    stop('c must be positive.')
  }
  if ((k %% 1 != 0) | (k < 1)) {
    stop('k must be a positive integer')
  }
  if (estimator == 'huber') {
    if (k == 1) {
      factor1 <- (k / 2) * lowergamma(k / 2, 0.5 * c^2)
      factor3 <- (c^(k - 1)) * (2^(-k / 2)) * exp(-0.5 * c^2)
    } else {
      factor1 <- (k / 2) * lowergamma(k / 2, 0.5 * c^2) + c * (k - 1) * (2^-1.5) * uppergamma((k - 1) / 2, 0.5 * c^2)
      factor3 <- (c^(k - 1)) * (2^(-k / 2)) * exp(-0.5 * c^2) + (k - 1) * (2^-1.5) * uppergamma((k - 1) / 2, 0.5 * c^2)
    }
    factor2 <- lowergamma((k + 2) / 2, 0.5 * c^2) + (0.5 * c^2) * uppergamma(k / 2, 0.5 * c^2)
    factor4 <- c * uppergamma(k / 2, 0.5 * c^2)
  } else if (estimator == 'tukey') {
    factor1 <- (2 * (k + 4) / (c^4)) * lowergamma((k + 4) / 2, 0.5 * c^2) - (2 * (k + 2) / (c^2)) * lowergamma((k + 2) / 2, 0.5 * c^2) + (k / 2) * lowergamma(k / 2, 0.5 * c^2)
    factor2 <- lowergamma((k + 2) / 2, 0.5 * c^2) - (8 / (c^2)) * lowergamma((k + 4) / 2, 0.5 * c^2) + (24 / (c^4)) * lowergamma((k + 6) / 2, 0.5 * c^2) - (32 / (c^6)) * lowergamma((k + 8) / 2, 0.5 * c^2) + (16 / (c^8)) * lowergamma((k + 10) / 2, 0.5 * c^2)
    factor3 <- -(8 * (k + 4) / (c^5)) * lowergamma((k + 4) / 2, 0.5 * c^2) + (4 * (k + 2) / (c^3)) * lowergamma((k + 2) / 2, 0.5 * c^2) - c^(k - 1) * 2^(-((k - 2) / 2)) * exp(-0.5 * c^2)
    factor4 <- (16 / (c^3)) * lowergamma((k + 4) / 2, 0.5 * c^2) - (96 / (c^5)) * lowergamma((k + 6) / 2, 0.5 * c^2) + (192 / (c^7)) * lowergamma((k + 8) / 2, 0.5 * c^2) - (128 / (c^9)) * lowergamma((k + 10) / 2, 0.5 * c^2)
  } else {
    stop('the M-estimator must be one of huber or tukey')
  }
  numerator <- 2 * factor1 * factor3 * factor2 - (factor1^2) * factor4
  denominator <- (gamma((k + 2) / 2)) * factor2^2
  result <- numerator / denominator
  return(result)
}

#' Newton-Raphson method for the \code{are} function
#'
#' Finds the
#'
#'
#'
#' @param estimator M-type estimator (\code{'huber'} or \code{'tukey'}).
#' @param k Dimension of the manifold.
#' @param startingpoint Initial estimate for the Newton-Raphson method. May be determined after looking at a graph of the \code{are} function.
#' @param level The desired ARE to the \code{'l2'} estimator.
#' @return Positive multiplier of \eqn{\sigma}, the square root of the variance, used in the cutoff parameter, to give the desired level of efficiency.
#' @references Shin H.-Y., Oh H.-S. (2020). Robust Geodesic Regression. <arXiv>
#' @author Ha-Young Shin
#' @seealso \code{\link{are}}.
#' @examples
#' areNR('huber', 4, 2)
#' areNR('tukey', 90, 15)
#'
#' @export
are_nr <- function(estimator, k, startingpoint, level = 0.95) {
  if (estimator == 'huber') {
    if (level <= are('l1', k)) {
      stop('the ARE of the L1 estimator is greater than the proposed ARE level')
    }
  }
  if  ((level >= 1) | (level <= 0)) {
    stop('the proposed are level is invalid')
  }
  if (startingpoint < 0) {
    stop('the starting point cannot be negative')
  }
  old_c <- startingpoint + 5
  new_c <- startingpoint
  count <- 0
  while (abs(new_c - old_c) > 0.000001) {
    old_c <- new_c
    new_c <- old_c - (are(estimator, k, old_c) - level) / deriv(estimator, k, old_c)
    if (new_c < 0) {
      stop('try again with a new starting point; consider using a graph of the are function to pick a good starting point')
    }
    count <- count + 1
    if (count > 1000) {
      stop('try again with a new starting point; consider using a graph of the are function to pick a good starting point')
    }
  }
  return(new_c)
}

ip <- function(manifold, v1, v2) {
  if (length(v1) != length(v2)) {
    stop('v1 and v2 must have the same length')
  }
  if ((manifold == 'euclidean') | (manifold == 'sphere')) {
    result <- sum(v1 * v2)
  } else if (manifold == 'kendall') {
    result <- sum(v1 * Conj(v2))
  } else {
    stop('the manifold must be one of euclidean, sphere, or kendall')
  }
  return(result)
}

mag <- function(manifold, v) {abs(sqrt(ip(manifold, v, v)))}

#' Exponential map
#'
#'
#'
#' @param manifold Type of manifold (\code{'euclidean'}, \code{'sphere'}, or \code{'kendall'}).
#' @param p A vector representing a point on the manifold.
#' @param v A vector tangent to \code{p}.
#' @return A vector representing a point on the manifold.
#' @references
#' @author Ha-Young Shin
#' @seealso \code{\link{loga}}.
#' @example expo('sphere', c(1, 0, 0), c(0, 0, pi / 4))
#'
#' @export
expo <- function(manifold, p, v) {
  embedded <- length(p)
  if (embedded != length(v)) {
    stop('p and v must have the same length')
  }
  if (manifold == 'euclidean') {
    result <- p + v
  } else if (manifold == 'sphere') {
    magp <- mag(manifold, p)
    if (abs((magp - 1)) > 0.000001) {
      stop('p must be a unit vector')
    }
    if (abs(ip(manifold, p, v)) > 0.000001) {
      stop('v must be tangent to p')
    }
    p <- p / magp
    theta <- mag(manifold, v)
    if (theta == 0) {
      result <- p
    } else {
      e1 <- p
      e2 <- v / theta
      result <- cos(theta) * e1 + sin(theta) * e2
      result <- result / mag(manifold, result)
    }
  } else if (manifold == 'kendall') {
    meanp <- sum(p) / embedded
    if (abs((mag(manifold, p) - 1)) > 0.000001) {
      stop('p must be a unit vector')
    }
    if (abs(ip(manifold, p, v)) > 0.000001) {
      stop('v must be tangent to p')
    }
    if ((mag(manifold, meanp) > 0.000001) | (mag(manifold, sum(v) / embedded) > 0.000001)) {
      stop('p and v must be centered')
    }
    p <- (p - meanp) / mag(manifold, p - meanp)
    theta <- mag(manifold, v)
    if (theta == 0) {
      result <- p
    } else {
      e1 <- p
      e2 <- v / theta
      result <- cos(theta) * e1 + sin(theta) * e2
      result <- (result - sum(result) / embedded) / mag(manifold, result - sum(result) / embedded)
    }
  } else {
    stop('the manifold must be one of euclidean, sphere, or kendall')
  }
  return(result)
}

#' Logarithmic map
#'
#'
#'
#'
#'
#' @param manifold Type of manifold (\code{'euclidean'}, \code{'sphere'}, or \code{'kendall'}).
#' @param p1 A vector representing a point on the manifold.
#' @param p2 A vector representing a point on the manifold.
#' @return A vector tangent to \code{p1}.
#' @references
#' @author Ha-Young Shin
#' @seealso \code{\link{expo}}, \code{\link{dist}}.
#' @example loga('sphere', c(0, 1, 0), c(0, 0, 1))
#'
#' @export
loga <- function(manifold, p1, p2) {
  embedded <- length(p1)
  if (embedded != length(p2)) {
    stop('p1 and p2 must have the same length')
  }
  if (manifold == 'euclidean') {
    result <- p2 - p1
  } else if (manifold == 'sphere') {
    magp1 <- mag(manifold, p1)
    magp2 <- mag(manifold, p2)
    if ((abs((magp1 - 1)) > 0.000001) | (abs((magp2 - 1)) > 0.000001)) {
      stop('p1 and p2 must be unit vectors')
    }
    p1 <- p1 / magp1
    p2 <- p2 / magp2
    a <- max(min(ip(manifold, p1, p2), 1), -1)
    theta <- acos(a)
    tang <- p2 - a * p1
    if (mag(manifold, tang) == 0) {
      if (mag(manifold, p1 - p2) < 0.000001) {
        result <- numeric(embedded)
      } else if (mag(manifold, p1 + p2) < 0.000001) {
        stop('p2 is the antipode of p1 and is therefore not in the domain of the log map at p1')
      }
    } else {
      result <- theta * (tang / mag(manifold, tang))
    }
  } else if (manifold == 'kendall') {
    meanp1 <- sum(p1) / embedded
    meanp2 <- sum(p2) / embedded
    if ((abs((mag(manifold, p1) - 1)) > 0.000001) | (abs((mag(manifold, p2) - 1)) > 0.000001)) {
      stop('p1 and p2 must be unit vectors')
    }
    if ((mag(manifold, meanp1) > 0.000001) | (mag(manifold, meanp2) > 0.000001)) {
      stop('p1 and p2 must be centered')
    }
    p1 <- (p1 - meanp1) / mag(manifold, p1 - meanp1)
    p2 <-  (p2 - meanp2) / mag(manifold, p2 - meanp2)
    a <- ip(manifold, p1, p2)
    theta <- acos(max(min(abs(a), 1), -1))
    tang <- (a / abs(a)) * p2 - abs(a) * p1
    if (mag(manifold, tang) == 0) {
      result <- numeric(embedded)
    } else {
      result <- theta * (tang / mag(manifold, tang))
    }
  } else {
    stop('the manifold must be one of euclidean, sphere, or kendall')
  }
  return(result)
}

#' Geodesic distance between two points on a manifold
#'
#'
#'
#'
#'
#' @param manifold Type of manifold (\code{'euclidean'}, \code{'sphere'}, or \code{'kendall'}).
#' @param p1 A vector representing a point on the manifold.
#' @param p2 A vector representing a point on the manifold.
#' @return Riemannian distance between \code{p1} and \code{p2}.
#' @references
#' @author Ha-Young Shin
#' @seealso \code{\link{loga}}.
#' @example
#'
#' @export
dist <- function(manifold, p1, p2) {
  return(mag(manifold, loga(manifold, p1, p2)))
}

#' Parallel transport
#'
#'
#'
#'
#'
#' @param manifold Type of manifold (\code{'euclidean'}, \code{'sphere'}, or \code{'kendall'}).
#' @param p1 A vector representing a point on the manifold.
#' @param p2 A vector representing a point on the manifold.
#' @param v A vector tangent to \code{p1}.
#' @return A vector tangent to \code{p2}.
#' @references
#' @author Ha-Young Shin
#' @example
#'
#' @export
pt <- function(manifold, p1, p2, v) {
  embedded <- length(p1)
  if ((embedded != length(p2)) | (embedded != length(v))) {
    stop('p1, p2, and v must have the same length')
  }
  if (manifold == 'euclidean') {
    result <- v
  } else if (manifold == 'sphere') {
    if (abs(ip(manifold, p1, v)) > 0.000001) {
      stop('v must be tangent to p1')
    }
    p1 <- p1 / mag(manifold, p1)
    w <- loga(manifold, p1, p2)
    if (mag(manifold, w) == 0) {
      result <- v
    } else {
      e1 <- p1
      e2 <- w / mag(manifold, w)
      a <- ip(manifold, v, e2)
      invar <- v - a * e2
      t <- mag(manifold, w)
      result <- a * (cos(t) * e2 - sin(t) * e1) + invar
    }
  } else  if (manifold == 'kendall') {
    meanp1 <- sum(p1) / embedded
    meanp2 <- sum(p2) / embedded
    if ((abs((mag(manifold, p2) - 1)) > 0.000001) | (mag(manifold, meanp2) > 0.000001)) {
      stop('p2 must be a centered unit vector')
    }
    p1 <- (p1 - meanp1) / mag(manifold, p1 - meanp1)
    p2 <- (p2 - meanp2) / mag(manifold, p2 - meanp2)
    yi <- expo(manifold, p1, v)
    a <- ip(manifold, p1, p2)
    p2 <- (a / abs(a)) * p2 #p2 is now p2star
    if (abs(a) >= 1) {
      result <- loga(manifold, p2, yi)
    } else {
      b <- (1 - (abs(a))^2)^0.5
      p2tilda <- (p2 - abs(a) * p1) / b
      result <- v - (ip(manifold, v, p1)) * p1 - (ip(manifold, v, p2tilda)) * p2tilda + ((abs(a)) * (ip(manifold, v, p1)) - b * (ip(manifold, v, p2tilda))) * p1 + (b * (ip(manifold, v, p1)) + (abs(a)) * (ip(manifold, v, p2tilda))) * p2tilda
      result <- (Conj(a / abs(a))) * result
    }
  } else {
    stop('the manifold must be one of euclidean, sphere, or kendall')
  }
  return(result)
}

#' Loss function for M-type estimators
#'
#'
#'
#'
#'
#' @param t A real number
#' @param estimator M-type estimator (\code{'l2'}, \code{'l1'}, \code{'huber'}, or \code{'tukey'}).
#' @param cutoff Cutoff parameter for the \code{'huber'} and \code{'tukey'} estimators; should be \code{NULL} for the \code{'l2'} or \code{'l1'} estimators.
#' @return The loss, a positive real number.
#' @references
#' @author Ha-Young Shin
#' @seealso \code{\link{rho_prime}}.
#' @example
#'
#' @export
rho <- function(t, estimator, cutoff = NULL) {
  if (((estimator == 'huber') | (estimator == 'tukey')) & is.null(cutoff)) {
    stop('a cutoff value must be provided if the chosen m-estimator is huber or tukey')
  }
  if (!is.null(cutoff)) {
    if ((estimator == 'l2') | (estimator == 'l1')) {
      warning('l2 and l1 do not use a cutoff value')
    }
    if (cutoff < 0) {
      stop('the cutoff value cannot be negative')
    }
  }
  if (estimator == 'l2') {
    result <- 0.5 * t^2
  } else if (estimator == 'l1') {
    result <- abs(t)
  } else if (estimator == 'huber') {
    if (abs(t) < cutoff) {
      result <- 0.5 * t^2
    } else {
      result <- cutoff * abs(t) - 0.5 * cutoff^2
    }
  } else if (estimator == 'tukey') {
    if (abs(t) < cutoff) {
      result <- ((cutoff^2) / 6) * (1 - (1 - (t / cutoff)^2)^3)
    } else {
      result <- (cutoff^2) / 6
    }
  } else {
    stop('the M-estimator must be one of l2, l1, huber, or tukey')
  }
  return(result)
}

#' Derivative of the loss function for M-type estimators
#'
#'
#'
#'
#'
#' @inheritParams rho
#' @return The derivative.
#' @references
#' @author Ha-Young Shin
#' @seealso \code{\link{rho}}.
#' @example
#'
#' @export
rho_prime <- function(t, estimator, cutoff = NULL) {
  if (((estimator == 'huber') | (estimator == 'tukey')) & is.null(cutoff)) {
    stop('a cutoff value must be provided if the chosen m-estimator is huber or tukey')
  }
  if (!is.null(cutoff)) {
    if ((estimator == 'l2') | (estimator == 'l1')) {
      warning('l2 and l1 do not use a cutoff value')
    }
    if (cutoff < 0) {
      stop('the cutoff value cannot be negative')
    }
  }
  if (estimator == 'l2') {
    result <- t
  } else if (estimator == 'l1') {
    result <- sign(t)
  } else if (estimator == 'huber') {
    if (abs(t) < cutoff) {
      result <- t
    } else {
      result <- cutoff * sign(t)
    }
  } else if (estimator == 'tukey') {
    if (abs(t) < cutoff) {
      result <- t * ((1 - (t / cutoff)^2)^2) * sign(t)
    } else {
      result <- 0
    }
  } else {
    stop('the M-estimator must be one of l2, l1, huber, or tukey')
  }
  return(result)
}

eps <- function(manifold, p, V, x, y) {
  embedded <- length(p)
  sample_size <- dim(y)[2]
  if (dim(y)[1] != embedded) {
    stop('p and each data point in y must have the same length')
  }
  if (dim(x)[1] != sample_size) {
    stop('the sample sizes according to x and y do not match')
  }
  result <- matrix(, nrow = embedded, ncol = sample_size)
  shifts <- V %*% t(x)
  for (i in 1:sample_size) {
    predictions <- expo(manifold, p, shifts[, i])
    if ((manifold == 'sphere') & (mag(manifold, y[, i]-max(min(Re(ip(manifold, predictions, y[, i])), 1), -1) * predictions) == 0) & (mag(manifold, predictions + y[, i]) < 0.000001)) {
      result[, i] <- numeric(embedded)
    } else {
      result[, i] <-loga(manifold, predictions, y[, i])
    }
  }
  return(result)
}

error_sum <- function(manifold, p, V, x, y, estimator, cutoff = NULL) {
  sum <- 0
  res <- eps(manifold, p, V, x, y)
  for (i in 1:dim(y)[2]) {
    sum <- sum + rho(mag(manifold, res[, i]), estimator, cutoff)
  }
  return(sum)
}

jacobi <- function(manifold, p, v1, v2) {
  if ((length(p) != length(v1)) | (length(v1) != length(v2))) {
    stop('p, v1, and v2 must have the same length')
  }
  result <- vector("list")
  if (manifold == 'euclidean') {
    result$p <- v2
    result$V <- v2
  } else if (manifold == 'sphere') {
    if (mag(manifold, v1) != 0) {
      v2_0 <- pt(manifold, expo(manifold, p, v1), p, v2)
      v2_tan <- (ip(manifold, v2_0, (v1 / mag(manifold, v1)))) * (v1 / mag(manifold, v1))
      v2_orth <- v2_0 - v2_tan
      L <- mag(manifold, v1)
      result$p <- cos(L) * v2_orth + v2_tan
      result$V <- ((sin(L)) / L) * v2_orth + v2_tan
    } else {
      result$p <- v2
      result$V <- v2
    }
  } else if (manifold == 'kendall') {
    if (mag(manifold, v1) != 0) {
      j <- (0 + 1i) * v1
      v2_0 <- pt(manifold, expo(manifold, p, v1), p, v2)
      w_0 <- (Re(ip(manifold, v2_0, (j / mag(manifold, j))))) * (j / mag(manifold, j))
      u_0 <- v2_0 - w_0
      w_tan <- (Re(ip(manifold, w_0, (v1 / mag(manifold, v1))))) * (v1 / mag(manifold, v1))
      w_orth <- w_0 - w_tan
      u_tan <- (Re(ip(manifold, u_0, (v1 / mag(manifold, v1))))) * (v1 / mag(manifold, v1))
      u_orth <- u_0 - u_tan
      L <- mag(manifold, v1)
      result$p <- cos(L) * u_orth + cos(2 * L) * w_orth + u_tan + w_tan
      result$V <- ((sin(L)) / L) * u_orth + ((sin(2 * L)) / (2 * L)) * w_orth + u_tan + w_tan
    } else {
      result$p <- v2
      result$V <- v2
    }
  }
  return(result)
}

grad <- function(manifold, p, V, x, y, estimator, cutoff = NULL) {
  n <- dim(x)[2]
  result <- vector("list")
  result$p <- numeric(length(p))
  result$V <- matrix(0L, nrow = length(p), ncol = n)
  res <- eps(manifold, p, V, x, y)
  if (n == 1) {
    for (i in 1:dim(y)[2]) {
      if (mag(manifold, res[, i]) > 0.000001) {
        multiplier <- rho_prime(mag(manifold, res[, i]), estimator, cutoff)
        jf <- jacobi(manifold, p, x[i, 1] * as.vector(V), (res[, i] / mag(manifold, res[, i])))
        result$p <- result$p - multiplier * jf$p
        result$V <- result$V - x[i, 1] * multiplier * jf$V
      }
    }
  } else {
    shifts <- V %*% t(x)
    for (i in 1:dim(y)[2]) {
      if (mag(manifold, res[, i]) > 0.000001) {
        multiplier <- rho_prime(mag(manifold, res[, i]), estimator, cutoff)
        approxjf <- pt(manifold, expo(manifold, p, shifts[, i]), p, (res[, i] / mag(manifold, res[, i])))
        result$p <- result$p - multiplier * approxjf
        for (h in 1:n) {
          result$V[, h] <- result$V[, h] - x[i, h] * multiplier * approxjf
        }
      }
    }
  }
  return(result)
}

#' Check for presence on manifold, and projection onto manifold
#'
#'
#'
#'
#'
#' @param manifold Type of manifold (\code{'euclidean'}, \code{'sphere'}, or \code{'kendall'}).
#' @param y A matrix or data frame whose columns should represent points on the manifold.
#' @return a named list containing
#'  \item{on} {a logical vector describing whether or not each column of \code{y} is on the manifold.}
#'  \item{data} {a matrix of data frame of the same dimensions as \code{y}; each column of \code{y} has been forced onto the manifold if it is not already on it.}
#' @references
#' @author Ha-Young Shin
#'
#' @export
onmanifold <- function(manifold, y) {
  result <- vector("list")
  if (manifold == 'euclidean') {
    sample_size <- dim(y)[2]
    result$on <- !logical(sample_size)
    result$data <- y
  } else if (manifold == 'sphere') {
    sample_size <- dim(y)[2]
    mags <- vector(length = sample_size)
    ons <- vector(length = sample_size)
    for (i in 1:sample_size) {
      mags[i] <- mag(manifold, y[, i])
      if (abs(mags[i] - 1) > 0.000001) {
        ons[i] <- FALSE
      } else {
        ons[i] <- TRUE
      }
      y[, i] <- y[, i] / mags[i]
    }
    result$on <- ons
    result$data <- y
  } else if (manifold == 'kendall') {
    embedded <- dim(y)[1]
    sample_size <- dim(y)[2]
    mags <- vector(length = sample_size)
    means <- vector(length = sample_size)
    ons <- vector(length = sample_size)
    for (i in 1:sample_size) {
      mags[i] <- mag(manifold, y[, i])
      means[i] <- sum(y[, i]) / embedded
      if ((abs(mags[i] - 1) > 0.000001) | (mag(manifold, means[i]) > 0.000001)) {
        ons[i] <- FALSE
      } else {
        ons[i] <- TRUE
      }
      y[, i] <- (y[, i] - means[i]) / mag(manifold, y[, i] - means[i])
    }
    result$on <- ons
    result$data <- y
  } else {
    stop('the manifold must be one of euclidean, sphere, or kendall')
  }
  return(result)
}

#' Gradient descent for (robust) geodesic regression
#'
#'
#'
#'
#'
#' @param manifold Type of manifold (\code{'euclidean'}, \code{'sphere'}, or \code{'kendall'}).
#' @param x A matrix or data frame of independent variables; the rows and columns represent the subjects and independent variables, respectively.
#' @param y A matrix or data frame whose columns represent points on the manifold.
#' @param estimator M-type estimator (\code{'l2'}, \code{'l1'}, \code{'huber'}, or \code{'tukey'}).
#' @param c Multiplier of \eqn{\sigma}, the square root of the variance, used in the cutoff parameter for the \code{'huber'} and \code{'tukey'} estimators; should be \code{NULL} for the \code{'l2'} or \code{'l1'} estimators.
#' @param maxiter Maximum number of gradient descent steps before ending the algorithm.
#' @return A named list containing
#'  \item{p} {a vector representing the estimate of the initial point on the manifold}
#'  \item{V} {a matrix representing the estimate of the initial velocities for each independent variable; the columns represent the independent variables.}
#'  \item{iteration} {number of gradient descent steps taken.}
#' @references
#' @author Ha-Young Shin
#' @seealso code{\link{intrinsiccenter}}.
#'
# '@export
gr <- function(manifold, x, y, estimator, c = NULL, maxiter = 100000) {
  if (((estimator == 'huber') | (estimator == 'tukey')) & is.null(c)) {
    stop('a c value must be provided if the chosen m-estimator is huber or tukey')
  }
  if (!is.null(c)) {
    if ((estimator == 'l2') | (estimator == 'l1')) {
      warning('l2 and l1 do not use a c value')
    }
    if (c <= 0) {
      stop('c must be positive')
    }
  }
  ondata <- onmanifold(manifold, y)
  if (any(!(ondata$on))) {
    stop('all data points in y must lie on the manifold')
  }
  y <- ondata$data
  embedded <- dim(y)[1]
  sample_size <- dim(y)[2]
  n <- dim(x)[2]
  allequal <- c()
  for (var in 1:n) {
    # Deals with case when all of the data for one of the independent variables are equal
    if (length(unique(x[, var])) == 1) {
      x[, var] <- numeric(sample_size)
      allequal <- c(allequal, var)
    }
  }
  if (manifold == 'sphere') {
    same <- 0
    antipode <- 0
    if (sample_size > 1) {
      for (i in 2:sample_size) {
        if (mag(manifold, y[, 1] + y[, i]) == 0) {
          antipode <- antipode + 1
        } else if (mag(manifold, y[, 1] - y[, i]) == 0) {
          same <- same + 1
        } else {
          break
        }
        if ((antipode + same == sample_size) & (antipode > 0)) {
          stop('there is no unique solution as all the data points are on antipodes of the sphere, with at least one data point on either antipode')
        }
      }
    }
  }
  if (any(abs(colMeans(x)) > 0.000001)) {
    warning('the mean of the data for at least one of your independent variables is not zero; the x data should be centered for best results')
  }
  if  (length(allequal) == n) {
    current_p <- y[, 1]
  } else {
    current_p <- gr(manifold, t(t(numeric(sample_size))), y, estimator, c, maxiter)$p
  }
  current_V <- matrix(0L, nrow = embedded, ncol = n)
  old_p <- current_p
  old_V <- current_V
  count <- 0
  alt_count <- 0
  cutoff <- NULL
  if ((estimator == 'huber') | (estimator == 'tukey')) {
    xi <- (2 * Pinv(dim / 2, 0.5))^0.5
    deviations <- vector(length = sample_size)
    current_shifts <- current_V %*% t(x)
    for (i in 1:dim(y)[2]) {
      deviations[i] <- dist(manifold, expo(manifold, current_p, current_shifts[, i]), y[, i])
    }
    mad <- median(deviations)
    sigma <- mad / xi
    cutoff <- c * sigma
  }
  step <- grad(manifold, current_p, current_V, x, y, estimator, cutoff)
  V_diffs <- vector(length = n)
  for (h in 1:n) {
    V_diffs[h] <- mag(manifold, (pt(manifold, old_p, current_p, old_V[, h]) - current_V[, h]))
  }
  if (manifold == 'euclidean') {
    lambda <- 0.1
  } else if ((manifold == 'sphere') | (manifold == 'kendall')) {
    lambda <- min((1 / mag(manifold, step$p)), 0.1)
  }
  while ((count == 0) | ((count < maxiter) & (alt_count < 100000) & ((dist(manifold, old_p, current_p) > 0.0000001) | (any(V_diffs > 0.0000001))))) {
    new_p <- expo(manifold, current_p, -lambda * step$p)
    new_V <- matrix(, nrow = embedded, ncol = n)
    for (h in 1:n) {
      new_V[, h] <- pt(manifold, current_p, new_p, current_V[, h] - lambda * step$V[, h])
    }
    if (error_sum(manifold, current_p, current_V, x, y, estimator, cutoff) >= error_sum(manifold, new_p, new_V, x, y, estimator, cutoff)) {
      alt_count <- 0
      old_p <- current_p
      old_V <- current_V
      current_p <- new_p
      current_V <- new_V
      if ((estimator == 'huber') | (estimator == 'tukey')) {
        current_shifts <- current_V %*% t(x)
        for (i in 1:sample_size) {
          deviations[i] <- dist(manifold, expo(manifold, current_p, current_shifts[, i]), y[, i])
        }
        mad <- median(deviations)
        sigma <- mad / xi
        cutoff <- c * sigma
      }
      step <- grad(manifold, current_p, current_V, x, y, estimator, cutoff)
      for (h in 1:n) {
        V_diffs[h] <- mag(manifold, (pt(manifold, old_p, current_p, old_V[, h]) - current_V[, h]))
      }
      if (manifold == 'euclidean') {
        lambda <- 8 * lambda
      } else if ((manifold == 'sphere') | (manifold == 'kendall')) {
        lambda <- min((1 / mag(manifold, step$p)), 8 * lambda)
      }
      count <- count + 1
    } else {
      lambda <- lambda / 2
      alt_count <- alt_count + 1
    }
  }
  result <- vector("list")
  result$p <- current_p
  current_V[, allequal] <- NA
  result$V <- current_V
  result$iteration <- count
  return(result)
}

#' Gradient descent for location based on M-type estimators
#'
#'
#'
#'
#'
#' @param manifold Type of manifold (\code{'euclidean'}, \code{'sphere'}, or \code{'kendall'}).
#' @param y A matrix or data frame whose columns represent points on the manifold.
#' @param estimator M-type estimator (\code{'l2'}, \code{'l1'}, \code{'huber'}, or \code{'tukey'}).
#' @param c Multiplier of \eqn{\sigma}, the square root of the variance, used in the cutoff parameter for the \code{'huber'} and \code{'tukey'} estimators; should be \code{NULL} for the \code{'l2'} or \code{'l1'} estimators.
#' @param maxiter Maximum number of gradient descent steps before ending the algorithm.
#' @return A vector representing the location estimate
#' @references
#' @author Ha-Young Shin
#' @seealso code{\link{gr}}, \code{\link[RiemBase]{rbase.mean}}, \code{\link[RiemBase]{rbase.median}}.
#'
#' @export
intrinsic_location <- function(manifold, y, estimator, c = NULL) {
  sample_size <- dim(y)[2]
  return(gr(manifold, t(t(numeric(sample_size))), y, estimator, c = NULL)$p)
}
